{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af365c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "plt.rcParams['figure.figsize'] = (24, 16)\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0902b",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65eb24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directories(top_path, output_path):\n",
    "    \"\"\"\n",
    "    This file takes the path where are the D1NAMO data is in and copy the file structure to the \n",
    "    preprocessed data directory.\n",
    "    \n",
    "    top_path = is where the D1NAMO data is saved to\n",
    "    output_path = where the file structure for the output data will be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    for subject_type in os.listdir(top_path):\n",
    "        try:\n",
    "            os.mkdir(output_path+subject_type)\n",
    "        except:\n",
    "            pass\n",
    "        for subject_ID in os.listdir(top_path+subject_type):\n",
    "            try:\n",
    "                os.mkdir(\"data/processed_data/\"+subject_type+\"/\"+subject_ID)\n",
    "            except:\n",
    "                pass\n",
    "            for filename in os.listdir(top_path+subject_type+\"/\"+subject_ID):\n",
    "                try:\n",
    "                    if len(filename.split(\".\")) == 1: \n",
    "                        os.mkdir(\"data/processed_data/\"+subject_type+\"/\"+subject_ID+\"/\"+filename)\n",
    "                except:\n",
    "                    pass\n",
    "            for filename in os.listdir(top_path+subject_type+\"/\"+subject_ID+\"/sensor_data\"):\n",
    "                try:\n",
    "                    if len(filename.split(\".\")) == 1: \n",
    "                        os.mkdir(\"data/processed_data/\"+subject_type+\"/\"+subject_ID+\"/sensor_data/\"+filename)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74edb05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_food_file(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This loads in each food file for each unique subject and processes it.\n",
    "    \n",
    "    First I will join date and time into one column.\n",
    "    Since I don't plan on using computer vision I will drop the picture column.\n",
    "    \n",
    "    Then I will fix mistakes in the data entry.\n",
    "    Mainly in the columns:\n",
    "        1. balance\n",
    "        2. quality\n",
    "        3. calories\n",
    "    \"\"\"\n",
    "    # Only health subjects contain the date and time columns.\n",
    "    \n",
    "    try:\n",
    "        join_date_time(df, \"date\", \"time\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    df.drop(columns=[\"picture\"],inplace=True)\n",
    "    \n",
    "    df.replace('No information', np.nan,inplace=True)\n",
    "    \n",
    "    if '8 Balance\"\"' in df[\"balance\"]:\n",
    "        df.replace('8 Balance\"\"', \"Balance\",inplace=True)\n",
    "    \n",
    "    if df[\"calories\"].dtypes == object:\n",
    "        find_correct_calorie_column(df)\n",
    "        \n",
    "def find_correct_calorie_column(df):\n",
    "    \n",
    "    for i, value in enumerate(df[\"calories\"]):   \n",
    "        if type(value) != float: # This should filter out all Null values\n",
    "            try:\n",
    "                df[\"calories\"][i] = int(value)\n",
    "            except ValueError:\n",
    "                if value in [\"Balance\",\"Unbalance\"]:\n",
    "                    df[\"balance\"][i] = value\n",
    "                elif value in ['Good quality', 'Medium quality', 'Low quality']:\n",
    "                    df[\"quality\"][i] = value\n",
    "                elif type(df[\"description\"][i]) == float:\n",
    "                    df[\"description\"][i] = value\n",
    "                df[\"calories\"][i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f229e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_glucose_file(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This loads in each glucose file for each unique subject and processes it.\n",
    "    \n",
    "    First I will join date and time into one column.\n",
    "    \n",
    "    Then I will fix mistakes in the data entry in glucose column.\n",
    "    \"\"\"\n",
    "    # Only health subjects contain the date and time columns.\n",
    "    \n",
    "    try:\n",
    "        join_date_time(df, \"date\", \"time\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "    df.replace('No information', np.nan,inplace=True)\n",
    "    \n",
    "    if df[\"glucose\"].dtypes == object:\n",
    "        fix_glucose_column(df)\n",
    "        \n",
    "def fix_glucose_column(df):\n",
    "    \"\"\"\n",
    "    I have come across errors in the data entry where a : is used instead of a .\n",
    "    I will find the mistakes and convert to the right format.\n",
    "    \"\"\"\n",
    "    for i, value in enumerate(df[\"glucose\"]):   \n",
    "        if type(value) != float: # This should filter out all Null values\n",
    "            try:\n",
    "                df[\"glucose\"][i] = float(value)\n",
    "            except ValueError:\n",
    "                df[\"glucose\"][i] = float(value.replace(':', \".\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "142ebee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_date_time(df, date_col, time_col):\n",
    "    new_df = pd.to_datetime(df[date_col].astype(str) + ' ' +df[time_col].astype(str))\n",
    "    df.insert(2, 'datetime', new_df)\n",
    "    df.drop(columns=[date_col, time_col],inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da98e3de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_subjects(df,colName, title, xlabel):   \n",
    "    fontdict = {\"fontsize\":20}\n",
    "    plt.barh(df.index, df[colName],)\n",
    "    plt.title(title,fontdict)\n",
    "    plt.ylabel('Subject ID',fontdict)\n",
    "    plt.xlabel(xlabel,fontdict)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78da83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplot(df, title):\n",
    "    fontdict = {\"fontsize\":20}\n",
    "    plt.title(title)\n",
    "    plt.title(title,fontdict)\n",
    "    plt.xlabel('Subject ID',fontdict)\n",
    "    plt.ylabel(\"Glucose Level\",fontdict)\n",
    "    sns.boxplot(data=df, width = 0.5,orient=\"horizontal\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569e6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_top_subjects(calories, glucose, n):\n",
    "    myDict = {}\n",
    "    for i, key in enumerate(calories.index):\n",
    "        myDict[key] = i\n",
    "    for i, key in enumerate(glucose.index):\n",
    "        myDict[key] += i\n",
    "    return pd.DataFrame(\n",
    "        index=myDict.keys(), \n",
    "        data=myDict.values(),\n",
    "        columns=[\"Count\"]).sort_values(by=\"Count\",\n",
    "        ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c206c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(diabetes, healthy, included_012_diabetes=True):\n",
    "    top_path = \"data/D1NAMO/\"\n",
    "    output_path = \"data/processed_data/\"\n",
    "    \n",
    "    for subject in diabetes.index:\n",
    "        copy_file_function(subject,\"diabetes_subset\")\n",
    "        \n",
    "    for subject in healthy.index:\n",
    "        copy_file_function(subject,\"healthy_subset\")\n",
    "        \n",
    "    if included_012_diabetes:\n",
    "        copy_file_function(\"012_diabetes\",\"healthy_subset\")\n",
    "        \n",
    "def copy_file_function(subject,subject_type):\n",
    "    # Copy the glucose file\n",
    "    src = f\"{top_path}{subject_type}/{subject}/\"\n",
    "    dst = f\"{output_path}{subject_type}/{subject}/\"\n",
    "    shutil.copy(f\"{src}glucose.csv\", f\"{dst}glucose.csv\")\n",
    "    for day in os.listdir(f\"{src}sensor_data\"):\n",
    "        if day != \".DS_Store\":\n",
    "            try:\n",
    "                shutil.copy(f\"{src}sensor_data/{day}/{day+'_Summary.csv'}\", f\"{dst}sensor_data/{day}/{day+'_Summary.csv'}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"No such file or directory: {src}sensor_data/{day}/{day+'_Summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42302d30",
   "metadata": {},
   "source": [
    "### Data Overview\n",
    "\n",
    "Two different subject groups:\n",
    "\n",
    "1. Healthy Subjects  \n",
    "    This contains 20 subjects (1 with diabetes but treated to the same conditions as the healthy subjects)\n",
    "2. Diabetes Subjects  \n",
    "    This contains 9 subjects.\n",
    "\n",
    "Data is collected over a 4 day period.\n",
    "\n",
    "For this section I will only look at the following datasets.\n",
    "\n",
    "1. food.csv\n",
    "2. glucose.csv\n",
    "3. insulin.csv (diabete subset)\n",
    "4. annnotations.csv (healthy subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54410964",
   "metadata": {},
   "source": [
    "### Healthy Subjects\n",
    "Files to process  \n",
    "**food.csv**:\n",
    "\n",
    "1. Join the *date* *and* time column as one.  \n",
    "2. Remove the *pictureI*D column since there isn't enough annotated pictures to do anything interesting with.\n",
    "\n",
    "**glucose.csv**\n",
    "\n",
    "1. Join the *date* and *time* column as one. \n",
    "2. Remove the *comments* column since most subjects didn't make a comment.\n",
    "3. Convert the *type* column to a numeric value.  \n",
    "    1. This column represents when a subject measured their glucose level. e.g. BL = before lunch, AB = after breakfast\n",
    "    \n",
    "**annotations.csv**\n",
    "\n",
    "This file was intended to contain extra data about the subjects daily activities, such as exercise but much subjects left blank. For this reason I will ignore this file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabeb28a",
   "metadata": {},
   "source": [
    "### Diabetes Subjects\n",
    "Files to process  \n",
    "**food.csv**:\n",
    "\n",
    "1. Unlike the other subjects this did not contain a date or time column.\n",
    "2. Remove the *pictureI*D column since there isn't enough annotated pictures to do anything interesting with.\n",
    "\n",
    "It is clear that some subjects didn't include as much data as others.\n",
    "\n",
    "**glucose.csv**\n",
    "\n",
    "1. Join the *date* and *time* column as one. \n",
    "2. Remove the *comments* column since most subjects didn't make a comment.\n",
    "3. *Type* is the method the glucose was measured, cgm automatically measured every 5 minutes while manual was randomly done by the subject. Some subjects manually checked less frequently.\n",
    "\n",
    "    \n",
    "    \n",
    "**insulin.csv**\n",
    "\n",
    "1. Join the *date* and *time* column as one. \n",
    "2. Unclear what fast and slow insulin means. Could investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704fa44",
   "metadata": {},
   "source": [
    "Copy the file stucture from the D1NAMO directory to the processed_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c45591f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data/D1NAMO/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m top_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/D1NAMO/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/processed_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcreate_directories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mcreate_directories\u001b[1;34m(top_path, output_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_directories\u001b[39m(top_path, output_path):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    This file takes the path where are the D1NAMO data is in and copy the file structure to the \u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    preprocessed data directory.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    output_path = where the file structure for the output data will be saved.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subject_type \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m             os\u001b[38;5;241m.\u001b[39mmkdir(output_path\u001b[38;5;241m+\u001b[39msubject_type)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data/D1NAMO/'"
     ]
    }
   ],
   "source": [
    "top_path = \"data/D1NAMO/\"\n",
    "output_path = \"data/processed_data/\"\n",
    "\n",
    "create_directories(top_path,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d18df",
   "metadata": {},
   "source": [
    "### Simple data analysis\n",
    "\n",
    "In this section I will explore various aspects of the files:\n",
    "\n",
    "1. food.csv\n",
    "2. glucose.csv\n",
    "3. insulin.csv (diabete subset)\n",
    "4. annnotations.csv (healthy subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the food.csv I will check if there are any incorrected values in the balance and quality columns\n",
    "unique_balance = set()\n",
    "unique_quality = set()\n",
    "for subject_type in os.listdir(top_path):\n",
    "    for subject_ID in os.listdir(top_path+subject_type):\n",
    "        df = pd.read_csv(\"data/D1NAMO/\"+subject_type+\"/\"+subject_ID+\"/food.csv\")\n",
    "        unique_balance = unique_balance.union(set(df[\"balance\"]))\n",
    "        unique_quality = unique_quality.union(set(df[\"quality\"]))\n",
    "print(unique_balance)\n",
    "print(unique_quality)\n",
    "\n",
    "# Some mistakes are '8 Balance' which I will convert to just 'Balance' and 'No information' I will impute as a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5e38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For the food.csv file I will look at the data type of each column and see if I see anything interesting\n",
    "like a data type which doesn't belong in the coloumn.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "balance_dtypes = []\n",
    "quality_dtypes = []\n",
    "description_dtypes = []\n",
    "calories_dtypes = []\n",
    "for subject_type in os.listdir(top_path):\n",
    "    for subject_ID in os.listdir(top_path+subject_type):\n",
    "        df = pd.read_csv(\"data/D1NAMO/\"+subject_type+\"/\"+subject_ID+\"/food.csv\")\n",
    "        balance_dtypes.append(df[\"balance\"].dtype)\n",
    "        quality_dtypes.append(df[\"quality\"].dtype)\n",
    "        description_dtypes.append(df[\"description\"].dtype)\n",
    "        calories_dtypes.append(df[\"calories\"].dtype)\n",
    "print(set(balance_dtypes))\n",
    "print(set(quality_dtypes))\n",
    "print(set(description_dtypes))\n",
    "print(set(calories_dtypes))\n",
    "\n",
    "\"\"\"\n",
    "Calories should only be int or float so I believe this to be a mistake, \n",
    "I will check if this value belongs in another column.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4397b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will collect calorie data from the food.csv file\n",
    "\n",
    "calories_intake = {}\n",
    "for subject_type in os.listdir(top_path):\n",
    "    calories_intake[subject_type] = {}\n",
    "    for subject_ID in os.listdir(top_path+subject_type):\n",
    "        df = pd.read_csv(\"data/D1NAMO/\"+subject_type+\"/\"+subject_ID+\"/food.csv\")\n",
    "        process_food_file(df) # This function fixes some errors in the food.csv file.\n",
    "        \n",
    "        calories_intake[subject_type][f\"{subject_ID}\"] = {\"Total\": df[\"calories\"].sum(),\n",
    "                                                          \"Count\": df[\"calories\"].count(),\n",
    "                                                           \"Len\": len(df[\"calories\"])\n",
    "                                                          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7613b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dict into two dataframes, sorted by the number of entries made.\n",
    "\n",
    "diabetes_calories = pd.DataFrame(calories_intake[\"diabetes_subset\"]).T.sort_values(by=\"Len\")\n",
    "\n",
    "healthy_calories = pd.DataFrame(calories_intake[\"healthy_subset\"]).T.sort_values(by=\"Len\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93118780",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjects(diabetes_calories,\"Len\", \"Number of Meals Recorded (Diabetes Subjects)\", \"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e27e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjects(healthy_calories,\"Len\", \"Number of Meals Recorded (Healthy Subjects)\", \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fe1656",
   "metadata": {},
   "source": [
    "#### Insights from the graphs\n",
    "\n",
    "I can quickly see that some subjects were more thorough and inputed more data in comparison to others.  \n",
    "\n",
    "Diabetes Subject 003 only included 3 meals over a 4 day period. While subject 001 included 25+ meals.  \n",
    "For this reason I blieve that it will be difficult to use the food.csv file to complete further more complex analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will collect glucose data from the glucose.csv file\n",
    "glucose_levels = {}\n",
    "glucose_data = {}\n",
    "full_data = {}\n",
    "for subject_type in os.listdir(top_path):\n",
    "    glucose_levels[subject_type] = {}\n",
    "    glucose_data[subject_type] = {}\n",
    "    for subject_ID in os.listdir(top_path+subject_type):\n",
    "        \n",
    "        df = pd.read_csv(\"data/D1NAMO/\"+subject_type+\"/\"+subject_ID+\"/glucose.csv\")\n",
    "        process_glucose_file(df) # This function fixes some errors in the food.csv file.\n",
    "        \n",
    "        glucose_levels[subject_type][f\"{subject_ID}\"] = {\n",
    "        \"Mean\": df[\"glucose\"].mean(),\n",
    "        \"Count\": df[\"glucose\"].count() if subject_type == \"healthy_subset\" else df[df[\"type\"] == \"manual\"][\"glucose\"].count(),\n",
    "        \"STD\": np.std(df[\"glucose\"])\n",
    "                                                          }\n",
    "        \n",
    "        glucose_data[subject_type][f\"{subject_ID}\"] = df[\"glucose\"]\n",
    "        full_data[f\"{subject_type[0]}_{subject_ID}\"] = df[\"glucose\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dict into two dataframes, sorted by the number of entries made.\n",
    "diabetes_glucose_count = pd.DataFrame(glucose_levels[\"diabetes_subset\"]).T.sort_values(by=\"Count\")\n",
    "\n",
    "healthy_glucose_count = pd.DataFrame(glucose_levels[\"healthy_subset\"]).T.sort_values(by=\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3be4a",
   "metadata": {},
   "source": [
    "Since the diabetes subject have a device that automatically takes their glucose level, I will only look at manual measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db470be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjects(diabetes_glucose_count,\"Count\", \"Number of Glucose Measurements Taken (Diabetes Subjects)\", \"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subjects(healthy_glucose_count,\"Count\", \"Number of Measurements Taken (Healthy Subjects)\", \"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d79f8",
   "metadata": {},
   "source": [
    "#### Insights\n",
    "\n",
    "Once again it is clear that some subject (specifically the diabetes subset) were more thorough on thier data inputs than others.\n",
    "\n",
    "I have come to the conclusion that I would like to create a model which classifies if a subject is diabetec or not...\n",
    "\n",
    "I use different datasets to predicts:\n",
    "\n",
    "1. Base Case: Glucose levels\n",
    "2. Sensor data:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716884d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ac065",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_glucose_data =  pd.DataFrame(glucose_data[\"diabetes_subset\"])\n",
    "plot_boxplot(diabetes_glucose_data, \"Boxplot of Diabetes Subject's Glucose Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10810e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_glucose_data =  pd.DataFrame(glucose_data[\"healthy_subset\"])\n",
    "plot_boxplot(healthy_glucose_data, \"Boxplot of Healthy Subject's Glucose Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602c34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_glucose_data =  pd.DataFrame(full_data)\n",
    "plot_boxplot(full_glucose_data, \"Boxplot of Healthy Subject's Glucose Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_glucose_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_five_top_picks = pick_top_subjects(diabetes_calories, diabetes_glucose_count, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_five_top_picks = pick_top_subjects(healthy_calories, healthy_glucose_count, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_type in os.listdir(top_path):\n",
    "        try:\n",
    "            os.mkdir(output_path+subject_type)\n",
    "        except:\n",
    "            pass\n",
    "        for subject_ID in os.listdir(top_path+subject_type):\n",
    "            try:\n",
    "                os.mkdir(\"data/processed_data/\"+subject_type+\"/\"+subject_ID)\n",
    "            except:\n",
    "                pass\n",
    "            for filename in os.listdir(top_path+subject_type+\"/\"+subject_ID):\n",
    "                try:\n",
    "                    if len(filename.split(\".\")) == 1: \n",
    "                        os.mkdir(\"data/processed_data/\"+subject_type+\"/\"+subject_ID+\"/\"+filename)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624ac47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31da6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(diabetes_five_top_picks, healthy_five_top_picks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
